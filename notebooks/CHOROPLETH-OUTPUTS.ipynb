{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a crack at a choropleth map from the altair documentation.\n",
    "# states is a built-in datastructure that contains the map, and\n",
    "# statedata is a sequence of 50 random numbers that I will paint on the map.\n",
    "# Altiar wants the map and the data in the same data structure, so we\n",
    "# have to use transform_lookup (the equivalent of pd.join or VLOOKUP)\n",
    "# to either merge the map into the data or the data into the map\n",
    "# before there is enough data in one place to attempt a map\n",
    "\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')  # This is the map\n",
    "statedata = pd.DataFrame({\"value\":np.random.random(51)})      # This is bogus data\n",
    "statedata[\"id\"] = statedata.index\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode(\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(statedata, 'id', [\"value\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's nice.  But a little too blue. \n",
    "# Did I forget to specify .encode(color) ? \n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "statedata = pd.DataFrame({\"value\":np.random.random(51)})\n",
    "statedata[\"id\"] = statedata.index\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode(color=\"value:Q\"\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(statedata, 'id', [\"value\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's wrong with West Virginia, Virginia, Wyoming, and Washington?\n",
    "# Oh, the map has more than 50 regions.  How am I supposed to put \n",
    "# state data in the right place?  \n",
    "# Elsewhere in the documentation, the following toy dataset is used for \n",
    "# choropleth maps, and it seems to contain the  Statename -> magic map id number mapping\n",
    "\n",
    "# I can open it in a browser if my browser has a JSON viewer plugin.\n",
    "\n",
    "income = pd.read_json(\"https://vega.github.io/vega-datasets/data/income.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has lots of income data I don't care about, but it does have states and IDs.\n",
    "decoder={}\n",
    "for row in income.iloc():\n",
    "    decoder[row[\"name\"]] = row[\"id\"]\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(decoder.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, so it's DC and PR in this dataset, and there are gaps in the numbering where you \n",
    "# might expect American Samoa and Guam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fruitlessly searching the census website for 10 minutes, I got a \n",
    "# population chart from https://en.wikipedia.org/wiki/2010_United_States_census\n",
    "# and as you will see, I will come to regret it.\n",
    "\n",
    "population=pd.read_csv(\"state-population.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A word on separators.  Simple \"flat\" files have three puncuation marks:\n",
    "# line separators, which ususally don't give trouble, \n",
    "# field separators like tab, space, and comma, and\n",
    "# quotation marks.\n",
    "# Q:  Why are the quotation marks necessary?\n",
    "# A:  Because fields sometimes contain spaces, commas, tabs, or, sadly, newline characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An arcane piece of data lore for you: when you have to fit unruly variable-length \n",
    "# data into a flat format (not something structured like XML or JSON),\n",
    "# *put the variable-length field at the end* of the line.  One peice of very useful bioinformatics\n",
    "# workhorse software for a long time used spaces as field separators and had one field\n",
    "# that was allowed to contain spaces.  It was at the end of the line, so graduate students\n",
    "# around the world wrote parsers that separated fields with the first 17 spaces and left \n",
    "# the remaining spaces in the 18th field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D'oh.  Set field separator to tab.\n",
    "population=pd.read_csv(\"state-population.csv\", sep=\"\\t\")\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can't fool me, I've seen what commas do to the digestive system of a pandas.\n",
    "# I will remove them and add them as new comma-free columns \"2000\" and \"2010\"\n",
    "population[\"2000\"] = population[\"2000 Population\"].str.replace(\",\",\"\")\n",
    "population[\"2010\"] = population[\"2010 Population\"].str.replace(\",\",\"\")\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.sort_values(\"2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something is not right here.. my populations are sorted in alphabetical\n",
    "# (jargon lexciographic) order.  Let us ignore that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = population.sort_values(\"2010\")[\"2010\"].cumsum()\n",
    "cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shouldn't have ignored that.  cumsum() is not summing numbers but concatenating\n",
    "# strings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.sort_values(\"2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now really create numerical population columns\n",
    "population[\"2000\"] = pd.to_numeric(population[\"2000 Population\"].str.replace(\",\",\"\"))\n",
    "population[\"2010\"] = pd.to_numeric(population[\"2010 Population\"].str.replace(\",\",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative = population.sort_values(\"2010\")[\"2010\"].cumsum()\n",
    "cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is better.  Let's plot it.\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(np.arange(len(cumulative)), cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(cumulative)), cumulative)\n",
    "# Note this graph, *because of the way we constructed it*, has\n",
    "# \"first-derivative-like\" first differences positive and \n",
    "# \"second-derivative-like\" second differences also positive.\n",
    "#  Eeenteresting.  Not suspicion-inspiring at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the middle value is \n",
    "cumulative[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the final value is \n",
    "cumulative[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert more-cattle-than-people joke here\n",
    "cumulative[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fraction of the population in the smallest 26 states:\n",
    "cumulative[25]/cumulative[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't draw my population data on a map until I integrate the numerical \n",
    "# map IDs with the state name, and best practice when you have two pieces \n",
    "# of data in different data frames is to join them.  Let us examine our fields:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column named \"State\" to facilitate joining \n",
    "income[\"State\"] = income.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.join(income, on=\"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.join is complaining about data types.  Can I clean up the types?\n",
    "population.State = population.State.astype(str)\n",
    "income.State = income.State.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No that doesn't work ... seearch engine...  specify join fields with \n",
    "# DataFrame.set_index(\"fieldname\")\n",
    "population.set_index(\"State\").join(income.set_index(\"State\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait a minute, that looked like it joined but it didn't.  Why could it \n",
    "# be that \"California\" does not join with \"California\" ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"+population.State[0]+\"*\")\n",
    "print(\"*\"+income.State[0]+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That would do it.  population has trailing spaces in its state name column.\n",
    "# Can I just use square bracket notation on population.State?\n",
    "test = population.State[:-1]\n",
    "print(\"*\"+test[0]+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apparently not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can I use pd.Series.str and square brackets?\n",
    "test = population.State.str[:-1]\n",
    "print(\"*\"+test[0]+\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, I can.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to remember not to run that cell again or I'll be \n",
    "# vacationing in Michiga next summer.\n",
    "\n",
    "population[\"State\"] = population.State.str[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe joinpop, containing everything worthwhile from population and income:\n",
    "joinpop = population.set_index(\"State\").join(income.set_index(\"State\"), how=\"left\")\n",
    "joinpop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinpop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And add a Boolean column with \"bigger or smaller than 26th smallest state\"\n",
    "joinpop[\"flag\"] = (joinpop[\"2010\"] <=population.loc[25][\"2010\"])\n",
    "\n",
    "joinpop[\"flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including lots of duplicated population data.  (As long as I'm not summing it\n",
    "# I should be fine.)\n",
    "joinpop.id.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income.id.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinpop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to the map.  Merge joinpop.flag \n",
    "\n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode(\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(joinpop, 'id', [\"flag\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge joinpop[\"flag\" ]\n",
    "\n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode( \n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(joinpop, 'id', [\"flag\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include .encode(color=)\n",
    "\n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode( color=alt.Color(\"flag:N\")\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(joinpop, 'id', [\"flag\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And I could fine-tune the colors and the labels and get rid of the missing values \n",
    "# for PR and DC but I'm ready to declare victory for today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the actual numbers, we could plot the population data itself, \n",
    "# not just a large-small marker:\n",
    "\n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode( color=alt.Color(\"2010:N\")\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(joinpop, 'id', [\"flag\", \"2010\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ha, ha.  Not going to get full marks for that one. Population is not a categorical\n",
    "# variable, and bad things happen if you instruct altiar otherwise.  There are only 10\n",
    "# colors, so each color appears 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population must be quantitative \":Q\" in color specificaiton \n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "alt.Chart(states).mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode( color=alt.Color(\"2010:Q\")\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(joinpop, 'id', [\"flag\", \"2010\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert anti-Californian joke here, since they are eating most of the blue\n",
    "# ink being a large state with 33 million people.\n",
    "\n",
    "# What's the difference between an anti-Californian joke and an anti-Wyomingan joke?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.loc[0][\"2010\"]/population.loc[50][\"2010\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The anti-Californian joke gets 60x more poeple mad at you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to add a title \n",
    "states = alt.topo_feature(data.us_10m.url, feature='states')\n",
    "alt.Chart(states, title=\"Pointless choropleth map: states by 2010 census population\"\n",
    ").mark_geoshape(\n",
    "    stroke='white'\n",
    "  ).encode( color=alt.Color(\"2010:Q\")\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(joinpop, 'id', [\"flag\", \"2010\"])\n",
    ").project('albersUsa').properties(\n",
    "    width=500,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
